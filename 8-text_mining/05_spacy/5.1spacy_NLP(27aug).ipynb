{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24a0b6b-32d6-470f-af2e-ab675a2204db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U spacy(preferrable use this)\n",
    "#conda install -c conda-forge spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b4f6920-050f-4828-83f6-5ecfe2b263d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://spacy.io/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e9069a-7550-4d55-b0c1-6b2500eabca8",
   "metadata": {},
   "source": [
    "install this ananconda prompt \n",
    "\"python -m spacy download en_core_web_sm\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32020c6c-fd90-4759-9f50-3aba63f67502",
   "metadata": {},
   "source": [
    "as for regex we use r\" \" \n",
    "similarly for spacy we use u\" \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f212f37-0245-40a1-b7a9-32dc06e99ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import spacy and load the language library\n",
    "import spacy \n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3449ef88-e450-45f0-9875-de2fbdd04497",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a Doc object\n",
    "doc=nlp(u'Tesla is looking at buying U.S. startup for $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a535c5-dec7-42b8-b058-ccfdc28bc588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla\n",
      "is\n",
      "looking\n",
      "at\n",
      "buying\n",
      "U.S.\n",
      "startup\n",
      "for\n",
      "$\n",
      "6\n",
      "million\n"
     ]
    }
   ],
   "source": [
    "#print each token separately\n",
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c70cc78-17e4-4572-8ce6-5ab4e3a37f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN\n",
      "is AUX\n",
      "looking VERB\n",
      "at ADP\n",
      "buying VERB\n",
      "U.S. PROPN\n",
      "startup NOUN\n",
      "for ADP\n",
      "$ SYM\n",
      "6 NUM\n",
      "million NUM\n"
     ]
    }
   ],
   "source": [
    "#import spacy and load the language library\n",
    "import spacy \n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "#create a Doc object\n",
    "doc=nlp(u'Tesla is looking at buying U.S. startup for $6 million')\n",
    "\n",
    "#print each token separately\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb08b688-c289-4c2c-8f4d-6aed64f6cf52",
   "metadata": {},
   "source": [
    "#search on google for token pos in gfg and you will get the meaning all this meaning\n",
    "# Token Dependency\n",
    "### very very important pos,dependency tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e0cb712-abd1-4cc0-8d22-8e524db1cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.S. PROPN compound\n",
      "startup NOUN dobj\n",
      "for ADP prep\n",
      "$ SYM quantmod\n",
      "6 NUM compound\n",
      "million NUM pobj\n"
     ]
    }
   ],
   "source": [
    "#import spacy and load the language library\n",
    "import spacy \n",
    "nlp=spacy.load('en_core_web_sm')\n",
    "\n",
    "#create a Doc object\n",
    "doc=nlp(u'Tesla is looking at buying U.S. startup for $6 million')\n",
    "\n",
    "#print each token separately\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_,token.dep_)\n",
    "    #Predict syntactic dependencies.\n",
    "    #predicting syntactic dependencies involves\n",
    "    #identifying the grammaticatical structure of a sentence by determining how differnt words relate to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5116e5-bb45-4c2a-97ac-b1b757aa7dfe",
   "metadata": {},
   "source": [
    "#IN our whatsapp ,it suggests us words on the basis token dependeencies \n",
    "#also if we say I like samosa in cruisine which is the place in out of the world but our India has the food as SAmosa so using token dependency we can \n",
    "predict that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d814a26-a215-403e-8ae8-81ec5dbcbd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x2a0b0b3deb0>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x2a0b0b3e4b0>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x2a0ad908270>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x2a0b1b76510>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x2a0b0492550>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x2a0ad9083c0>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline#using this we will get all the nlp pipeline processes like tokenization,stemmer,lematization,etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6420573-16e6-45aa-8deb-76ebf3ea242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://spacy.io/usage/spacy-101#pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2fb748f-a6d8-4c16-97eb-56355c594e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names#it is the property not  a function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd33d12-9f64-481d-bbd3-c1418805e24c",
   "metadata": {},
   "source": [
    "Tokenization The first step in preprocessing text is to split up all the components parts(words and punctuation ) into \"tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88fe76bd-c0fb-4ae3-90ae-34f38f84b959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla PROPN nsubj\n",
      "is AUX aux\n",
      "n't PART neg\n",
      "   SPACE dep\n",
      "looking VERB ROOT\n",
      "into ADP prep\n",
      "startups NOUN pobj\n",
      "anymore ADV advmod\n",
      ". PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "doc2=nlp(u\"Tesla isn't   looking into startups anymore.\")\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.text,token.pos_,token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb166180-1d49-4538-b02f-ad07929601c9",
   "metadata": {},
   "source": [
    "#notice how isn't has been spliy into 2 tokens .SPacy recognize both the root verb is and the negation attached to it.NOTICE THAT also both the extended whitespace and the period at the end of the sentence are assigned their own tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1519c593-dab7-4072-b30e-a304aa3f05a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla isn't   looking into startups anymore."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb217ad9-9607-4999-b4f7-19cfd7161464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tesla"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3805a7a-379f-4295-9c50-b2b0fd408fe1",
   "metadata": {},
   "source": [
    "# POS \n",
    "https://spacy.io/usage/linguistic-features#pos-tagging\n",
    "# for dependencies\n",
    "dependencies :syntactic dependency assigned to each token\n",
    "https://spacy.io/api/annotion#dependency-parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66ae9b5b-4d78-445f-9e23-75acea837cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PROPN'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffe7124-5e3a-4c0d-8330-1027b8a2a346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4d85f9-f1ea-4233-a3ed-4cd59b8a65c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6dd37-0ab1-4796-9f9e-a2b77f4423c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1047fbb1-9df6-45a5-ad5d-2140041d79d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf6e04c-5bd3-46c9-9f21-ddb97f8416b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4fce42-9ffd-43d7-b5d7-119fb8ffc7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e191702a-501e-4579-8a37-5a06d32af257",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad3762bc-7b3a-48d6-bfc6-1748572fb758",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m life_quote\u001b[38;5;241m=\u001b[39mdoc3[\u001b[38;5;241m16\u001b[39m:\u001b[38;5;241m30\u001b[39m]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(life_quote)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'doc3' is not defined"
     ]
    }
   ],
   "source": [
    "life_quote=doc3[16:30]\n",
    "print(life_quote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f293980e-35d6-4c63-aaed-015f74b5c292",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'life_quote' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(life_quote)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'life_quote' is not defined"
     ]
    }
   ],
   "source": [
    "type(life_quote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5687e-1b4a-4226-b119-786343960112",
   "metadata": {},
   "source": [
    "# Sentences\n",
    "Certaain tokens inside a Doc object may also receive a \"start of sentence\" tag.While this doesn't immediately build a list of seneteces ,these tags enable the gneneration of senteces segments through Doc.sents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029d1053-7eb8-41ae-a07a-a3e0783b3819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654c994f-b2af-4368-b332-2f64bb8ecf4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a38f95e-25da-43c6-b7e0-ec57022fb644",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63effcf1-e43a-4a99-af9e-79a98c02ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import spacy and load the en_core_web_sm\n",
    "nlp=spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "145cd331-781d-43cb-bd90-24064e3f38e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We're moving to L.A.!\"\n"
     ]
    }
   ],
   "source": [
    "#creating a string that includes opening and closing quotation marks\n",
    "mystring='\"We\\'re moving to L.A.!\"'\n",
    "print(mystring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c108ee4c-18e1-4c2e-ac50-ace2f5e8c364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\" | We | 're | moving | to | L.A. | ! | \" | "
     ]
    }
   ],
   "source": [
    "#creating a Doc object and explore tokens\n",
    "doc=nlp(mystring)\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text,end=' | ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8aa0a35c-e920-490f-85ca-393505e1f9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WE're|here|to|help|!|Send|the|snail|-|mail|,|email|support@outsite.com|or|visit|us|at|https://www.oursite.com|!|"
     ]
    }
   ],
   "source": [
    "doc2=nlp(u\"WE're here to help !Send the snail-mail,email support@outsite.com or visit us at https://www.oursite.com!\")\n",
    "\n",
    "for token in doc2:\n",
    "    print(token.text,end='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4b1c1b4b-9e7f-4e4e-9b8a-798eb7fc27ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy will isolate punctuation that does not form an integral part of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "663465be-d189-4915-a443-9557bda77f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "5\n",
      "km\n",
      "NYC\n",
      "cab\n",
      "ride\n",
      "costs\n",
      "$\n",
      "10.30\n"
     ]
    }
   ],
   "source": [
    "doc3=nlp(u'A 5km NYC cab ride costs $10.30')\n",
    "\n",
    "for t in doc3:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12467b54-aa1f-4f66-a4d9-ad93f41f5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here the unit distance and dollar sign are assigned their own tokens ,yet the dollar amount is preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6aacdfcf-ba15-42c7-9a71-e9866eb31cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Punctuation that exists as part of the known abbrevation will be kept as part of the token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2c41f05f-b31d-401a-89dd-3547e6c7f3b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "visit\n",
      "St.\n",
      "Louis\n",
      "in\n",
      "the\n",
      "U.S.\n",
      "next\n",
      "year\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc4=nlp(u\"Let's visit St. Louis in the U.S. next year.\")\n",
    "\n",
    "for t in doc4:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f3d7cac-ed83-406e-a5fb-a2acbb3ce80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here the abrrevations for \"saint\" and \"United states are preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494866a1-3dbd-40ca-9ac7-91dc79aaa5b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
